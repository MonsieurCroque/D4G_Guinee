{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D4G CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3qr0ZB6LUQ4",
        "colab_type": "code",
        "outputId": "d87e0a6c-130f-4ae4-da18-e357f736d77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBZbfd5FTk5j",
        "colab_type": "code",
        "outputId": "b6885401-a299-4602-8e5d-3ffefe7bd60a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!pip install pyrsgis"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyrsgis\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/80/a74e3d968e2b74450d7de85dbd13785c73e8580a956fa56d14973266a9bf/pyrsgis-0.3.1-py3-none-any.whl\n",
            "Installing collected packages: pyrsgis\n",
            "Successfully installed pyrsgis-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idlZ5PZxJi8H",
        "colab_type": "code",
        "outputId": "e7bcf885-2c13-4bc5-9b7d-3b048acac1cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######################### Import des libraries #######################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.utils.data import Dataset, DataLoader, sampler\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.convert import changeDimension\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import scipy.signal\n",
        "import scipy.ndimage\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning! matplotlib_scalebar library not found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdvefVh4yrhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Import des données (tout en 1 seule tile) #########################\n",
        "\n",
        "#path = \"/content/drive/My Drive/D4G/Seredou_20190307_v2.tif\"\n",
        "path = \"/content/drive/My Drive/D4G/Seredou_20151203_v2.tif\"\n",
        "#path = \"/content/drive/My Drive/D4G/Seredou_20170205_v2.tif\"#encore des 4\n",
        "#path = \"/content/drive/My Drive/D4G/Diecke_20200215_crop.tif\"\n",
        "#path = \"/content/drive/My Drive/D4G/Diecke_20170205_crop.tif\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N830fS93Jof2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Import des données (1 seule tile) #########################\n",
        "\n",
        "path = \"/content/drive/My Drive/D4G/2_Seredou_2017/\"\n",
        "\n",
        "Test = \"2_Image_Seredou_32bits_20170205/S2A_20170205_seredou_32bits.tif\"\n",
        "MSI = \"2_MSI_Seredou_20170205/S2A_20170205_seredou_ZE_MSI_89.tif\"\n",
        "Truth = \"GroundTruth_Seredou_20170205/GroundTruth_20170205_seredou_ZE_89.tif\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQo7k4X1njZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Import des données (plusieurs tiles) #########################\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/D4G/1_Seredou_2015/\")\n",
        "\"\"\"\n",
        "#for testing\n",
        "test_raw = os.listdir(\"Images_test\")\n",
        "MSI_raw = os.listdir(\"MSI_test\")\n",
        "truth_raw = os.listdir(\"GroundTruth_test\")\n",
        "\n",
        "Test = {int(k.split(\"_\")[-1].split(\".tif\")[0].split(\"(\")[0]):('Images_test/'+k) for k in test_raw}\n",
        "MSI = {int(k.split(\"_\")[-1].split(\".tif\")[0].split(\"(\")[0]):('MSI_test/'+k) for k in MSI_raw}\n",
        "Truth = {int(k.split(\"_\")[-1].split(\".tif\")[0].split(\"(\")[0]):('GroundTruth_test/'+k) for k in truth_raw}\"\"\"\n",
        "\n",
        "\n",
        "#for prod\n",
        "test_raw = os.listdir(\"1_Images_Seredou_2015_32bits\")\n",
        "MSI_raw = os.listdir(\"1_MSI_Seredou_2015\")\n",
        "truth_raw = os.listdir(\"1_GroundTruth_Seredou_2015_tiled\")\n",
        "\n",
        "Test = {int(k.split(\"_\")[-1].split(\".tif\")[0]):('1_Images_Seredou_2015_32bits/'+k) for k in test_raw}\n",
        "MSI = {int(k.split(\"_\")[-1].split(\".tif\")[0]):('1_MSI_Seredou_2015/'+k) for k in MSI_raw}\n",
        "Truth = {int(k.split(\"_\")[-1].split(\".tif\")[0].split(\"(\")[0]):('1_GroundTruth_Seredou_2015_tiled/'+k) for k in truth_raw}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiKGhhz2GDRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Fonctions auxiliaires #########################\n",
        "\n",
        "def divide_test_in_squares(size, img):\n",
        "    return [img[:,int(i % img.shape[0])*size:((int(i % img.shape[0])+1)*size), int(i // img.shape[0])*size:(int(i // img.shape[0])+1)*size] for i in range(int(img.shape[0] * img.shape[1] // size**2))]\n",
        "\n",
        "def divide_image_in_squares(size, img):\n",
        "    return [img[int(i % img.shape[0])*size:((int(i % img.shape[0])+1)*size), int(i // img.shape[0])*size:(int(i // img.shape[0])+1)*size] for i in range(int(img.shape[0] * img.shape[1] // size**2))]\n",
        "\n",
        "def get_window(img, center, size):\n",
        "    \n",
        "    window = torch.tensor([0. for i in range(size*size)])\n",
        "    if center[0] + size // 2 < img.shape[0]:\n",
        "        i_begin = max(0,int(center[0]-size//2))\n",
        "        i_end = i_begin + size\n",
        "    else:\n",
        "        i_end = img.shape[0]\n",
        "        i_begin = i_end - size\n",
        "    if center[1] + size // 2 < img.shape[1]:\n",
        "        j_begin = max(0,int(center[1]-size//2))\n",
        "        j_end = j_begin + size\n",
        "    else:\n",
        "        j_end = img.shape[1]\n",
        "        j_begin = j_end - size\n",
        "\n",
        "    for i in range(i_begin, i_end):\n",
        "        for j in range(j_begin, j_end):\n",
        "            window[i - i_begin + size*(j - j_begin)] = float(img[i,j])\n",
        "    return window"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sta9I5a2KZcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Base de données (1 image) #########################\n",
        "\n",
        "class OurDataset(Dataset):\n",
        "    \"\"\"This dataset includes .... \"\"\"\n",
        "    \n",
        "    def __init__(self, path, Test, MSI, Truth, size, percentage, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path: (str) path to the images directory.\n",
        "        \"\"\"\n",
        "        #get data\n",
        "        ds1, data_MSI = raster.read(path + MSI, bands='all')\n",
        "        ds2, data_test = raster.read(path + Test, bands='all')\n",
        "        ds3, data_truth = raster.read(path + Truth, bands='all')\n",
        "\n",
        "        data_MSI[data_MSI < 0] = 0\n",
        "        data_test[data_test < 0] = 0\n",
        "        data_truth[data_truth < 0] = 0\n",
        "\n",
        "        self.MSI = divide_image_in_squares(size, data_MSI)\n",
        "        self.Test = divide_test_in_squares(size, data_test)\n",
        "        self.Truth = divide_image_in_squares(size, data_truth)\n",
        "  \n",
        "        self.size = size\n",
        "        self.mode = \"train\"\n",
        "        self.id_train, self.id_test = train_test_split([i for i in range(len(self.Test))], test_size = percentage, random_state=42, shuffle=True)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.mode == \"train\":\n",
        "            return len(self.id_train)\n",
        "        else:\n",
        "            return len(self.id_test)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: (int) the index of the subject/session whom data is loaded.\n",
        "        Returns:\n",
        "            sample: (dict) corresponding data described by the following keys:\n",
        "                scan: 11 channels value\n",
        "                mask: true value\n",
        "        \"\"\"\n",
        "        if self.mode == \"train\":\n",
        "            idx = self.id_train[id]\n",
        "        else:\n",
        "            idx = self.id_test[id]\n",
        "\n",
        "        feature_data = torch.tensor([[0. for i in range(11)] for j in range(self.Test[idx].shape[1]*self.Test[idx].shape[2])])\n",
        "        feature_truth = np.array([0 for j in range(self.Test[idx].shape[1]*self.Test[idx].shape[2])])\n",
        "\n",
        "        #On importe les données\n",
        "        for i in range(self.Test[idx].shape[1]):\n",
        "            for j in range(self.Test[idx].shape[2]):\n",
        "                feature_truth[i+self.Test[idx].shape[1]*j] = self.Truth[idx][i,j]\n",
        "                feature_data[i+self.Test[idx].shape[2]*j,10] = float(self.MSI[idx][i,j])\n",
        "\n",
        "                for k in range (10):\n",
        "                    feature_data[i+self.Test[idx].shape[2]*j,k] = float(self.Test[idx][k,i,j])\n",
        "\n",
        "        sample = {'data': feature_data, 'mask': feature_truth}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Put all the transforms of the dataset in training mode\"\"\"\n",
        "        self.transform.train()\n",
        "\n",
        "    def set_mode(self, mode):\n",
        "        \"\"\"Change mode of the database\"\"\"\n",
        "        self.mode = mode\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Put all the transforms of the dataset in evaluation mode\"\"\"\n",
        "        self.transform.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-sNVFN9yObk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Base de données (tout en 1 image) #########################\n",
        "\n",
        "class OurDataset(Dataset):\n",
        "    \"\"\"This dataset includes .... \"\"\"\n",
        "    \n",
        "    def __init__(self, path, size, percentage, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path: (str) path to the images directory.\n",
        "        \"\"\"\n",
        "        #get data\n",
        "        ds1, data = raster.read(path, bands='all')\n",
        "\n",
        "        data[data < 0] = 0\n",
        "\n",
        "        self.Test = divide_test_in_squares(size, data[:11,:,:])\n",
        "        self.Truth = divide_image_in_squares(size, data[11,:,:])\n",
        "        self.size = size\n",
        "        self.mode = \"train\"\n",
        "        self.id_train, self.id_test = train_test_split([i for i in range(len(self.Test))], test_size = percentage, random_state=42, shuffle=True)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.mode == \"train\":\n",
        "            return len(self.id_train)\n",
        "        else:\n",
        "            return len(self.id_test)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: (int) the index of the subject/session whom data is loaded.\n",
        "        Returns:\n",
        "            sample: (dict) corresponding data described by the following keys:\n",
        "                scan: 11 channels value\n",
        "                mask: true value\n",
        "        \"\"\"\n",
        "        if self.mode == \"train\":\n",
        "            idx = self.id_train[id]\n",
        "        else:\n",
        "            idx = self.id_test[id]\n",
        "\n",
        "        Test = self.Test[idx]\n",
        "\n",
        "        feature_data = torch.tensor([[[0. for i in range(11)] for p in range(64)] for j in range(Test.shape[1] * Test.shape[2])])\n",
        "        feature_truth = np.array([0 for j in range(Test.shape[1]*Test.shape[2])])\n",
        "\n",
        "        #On importe les données\n",
        "        for i in range(Test.shape[1]):\n",
        "            for j in range(Test.shape[2]):\n",
        "                feature_truth[i+self.Test[idx].shape[1]*j] = self.Truth[idx][i,j]\n",
        "                \n",
        "                for k in range (11):\n",
        "                    test = get_window(Test[:,:,k], (i,j,k), 8)\n",
        "                    for p in range(64):\n",
        "                        feature_data[i+self.Test[idx].shape[1]*j,p,k] = test[p]\n",
        "                        \n",
        "        sample = {'data': feature_data, 'mask': feature_truth}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Put all the transforms of the dataset in training mode\"\"\"\n",
        "        self.transform.train()\n",
        "\n",
        "    def set_mode(self, mode):\n",
        "        \"\"\"Change mode of the database\"\"\"\n",
        "        self.mode = mode\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Put all the transforms of the dataset in evaluation mode\"\"\"\n",
        "        self.transform.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32zCY29et_uY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Base de données (plusieurs images) #########################\n",
        "\n",
        "class OurDataset(Dataset):\n",
        "    \"\"\"This dataset includes .... \"\"\"\n",
        "    \n",
        "    def __init__(self, path, Test, MSI, Truth, percentage, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path: (str) path to the images directory.\n",
        "        \"\"\"\n",
        "        self.MSI = {}\n",
        "        self.Test = {}\n",
        "        self.Truth = {}\n",
        "        for key in MSI.keys():\n",
        "            _, self.MSI[key] = raster.read(MSI[key], bands='all')\n",
        "            _, self.Test[key] = raster.read(Test[key], bands='all')\n",
        "            _, self.Truth[key] = raster.read(Truth[key], bands='all')\n",
        "\n",
        "        self.mode = \"train\"\n",
        "        self.id_train, self.id_test = train_test_split([k for k in list(self.Test.keys())], test_size = percentage, random_state=42, shuffle=True)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.mode == \"train\":\n",
        "            return len(self.id_train)\n",
        "        else:\n",
        "            return len(self.id_test)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: (int) the index of the subject/session whom data is loaded.\n",
        "        Returns:\n",
        "            sample: (dict) corresponding data described by the following keys:\n",
        "                scan: 11 channels value\n",
        "                mask: true value\n",
        "        \"\"\"\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            idx = self.id_train[id] + 1\n",
        "        else:\n",
        "            idx = self.id_test[id] + 1\n",
        "\n",
        "                #get data\n",
        "        MSI = self.MSI[idx]\n",
        "        Test = self.Test[idx]\n",
        "        Truth = self.Truth[idx]\n",
        "        \n",
        "        MSI[MSI < 0] = 0\n",
        "        Test[Test < 0] = 0\n",
        "        Truth[Truth < 0] = 0\n",
        "        \n",
        "        feature_data = torch.tensor([[[0. for i in range(11)] for p in range(9)] for j in range(Test.shape[1] * Test.shape[2])])\n",
        "        feature_truth = np.array([0 for j in range(Test.shape[1]*Test.shape[2])])\n",
        "\n",
        "        #On importe les données\n",
        "        for i in range(Test.shape[1]):\n",
        "            for j in range(Test.shape[2]):\n",
        "                feature_truth[i+self.Test[idx].shape[1]*j] = self.Truth[idx][i,j]\n",
        "                \n",
        "                msi = get_window(MSI, (i,j), 3)\n",
        "                for p in range(9):\n",
        "                    feature_data[i+self.Test[idx].shape[1]*j,p,10] = msi[p]\n",
        "                                \n",
        "                for k in range (10):\n",
        "                    test = get_window(Test[:,:,k], (i,j,k), 3)\n",
        "                    for p in range(9):\n",
        "                        feature_data[i+self.Test[idx].shape[1]*j,p,k] = test[p]\n",
        "                        \n",
        "        sample = {'data': feature_data, 'mask': feature_truth}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Put all the transforms of the dataset in training mode\"\"\"\n",
        "        self.transform.train()\n",
        "\n",
        "    def set_mode(self, mode):\n",
        "        \"\"\"Change mode of the database\"\"\"\n",
        "        self.mode = mode\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Put all the transforms of the dataset in evaluation mode\"\"\"\n",
        "        self.transform.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG7nihqFQEq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, criterion, optimizer, n_epochs, size):\n",
        "    \"\"\"\n",
        "    Method used to train a CNN\n",
        "    \n",
        "    Args:\n",
        "        model: (nn.Module) the neural network\n",
        "        train_loader: (DataLoader) a DataLoader wrapping the dataset\n",
        "        criterion: (nn.Module) a method to compute the loss of a mini-batch of images\n",
        "        optimizer: (torch.optim) an optimization algorithm\n",
        "        n_epochs: (int) number of epochs performed during training\n",
        "\n",
        "    Returns:\n",
        "        best_model: (nn.Module) the trained neural network\n",
        "    \"\"\"\n",
        "    best_model = deepcopy(model)\n",
        "    train_best_loss = np.inf\n",
        "\n",
        "    batch_size = train_loader.batch_size\n",
        "    n = 10\n",
        "\n",
        "    n_batches = n//batch_size\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_eq = 0\n",
        "        total_nb = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader):\n",
        "            images, mask = torch.reshape(data['data'], ((size**2)*batch_size,64,11)), data['mask']\n",
        "            scans = torch.flatten(mask)\n",
        "            outputs = torch.reshape(model(images), (scans.shape[0],4))\n",
        "            loss = criterion(outputs, scans)\n",
        "            loss.backward()\n",
        "            soft_outputs = nn.functional.softmax(outputs)\n",
        "            total_eq += int(torch.sum(torch.argmax(soft_outputs,1) == scans))\n",
        "            total_loss += loss.item()\n",
        "            total_nb += scans.shape[0]\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader.dataset)\n",
        "        print('Epoch %i: loss = %f & accuracy = %f' % (epoch, mean_loss, total_eq/total_nb))\n",
        "\n",
        "        if mean_loss < train_best_loss:\n",
        "            best_model = deepcopy(model)\n",
        "            train_best_loss = mean_loss\n",
        "    \n",
        "    return best_model\n",
        "\n",
        "def test(model, data_loader, criterion, size):\n",
        "    \"\"\"\n",
        "    Method used to test a CNN\n",
        "    \n",
        "    Args:\n",
        "        model: (nn.Module) the neural network\n",
        "        data_loader: (DataLoader) a DataLoader wrapping the dataset\n",
        "        criterion: (nn.Module) a method to compute the loss of a mini-batch of images\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = data_loader.batch_size\n",
        "    n = 10000\n",
        "\n",
        "    n_batches = n//batch_size\n",
        "    nb_true = 0\n",
        "    nb_total = 0\n",
        "    size_loss = 0\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "            images, mask = torch.reshape(data['data'], ((size**2)*batch_size,64,11)), data['mask']\n",
        "            scans = torch.flatten(mask)\n",
        "            outputs = torch.reshape(model(images), (scans.shape[0],4))\n",
        "            loss = criterion(outputs, scans)\n",
        "            soft_outputs = nn.functional.softmax(outputs)\n",
        "            total_loss += loss.item()\n",
        "            size_loss += batch_size\n",
        "            nb_true += int(torch.sum(torch.argmax(soft_outputs,1) == scans))\n",
        "            nb_total += scans.shape[0]\n",
        "\n",
        "    print(\"Final loss : {} & accuracy : {}\".format(str(total_loss/ size_loss), str(nb_true/nb_total)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krUZkF84UOz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## Modèle ############################\n",
        "\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(64, 64, 4)\n",
        "        self.conv2 = nn.Conv1d(64, 64, 4)\n",
        "        self.conv3 = nn.Conv1d(64, 64, 4)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lin1 = nn.Linear(128,64)\n",
        "        self.lin2 = nn.Linear(64,32)\n",
        "        self.lin3 = nn.Linear(32,4)\n",
        "        self.lin4 = nn.Linear(16,16)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.lin1(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.lin2(x)\n",
        "        x = self.tanh(x)\n",
        "        x = self.lin3(x)\n",
        "        return x\n",
        "        #return nn.functional.softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg7aN91AKbgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## Database ############################\n",
        "\n",
        "size = 20\n",
        "database = OurDataset(path, size, 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEVKRJieJtJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## Prétraitement ############################\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "database.set_mode(\"train\")\n",
        "dataloader_train = DataLoader(database, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "model = Model()\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "criterion = nn.MultiMarginLoss(1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "n_epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsztqK9WQfRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################### Entrainement du modèle ##########################\n",
        "\n",
        "train(model, dataloader_train, criterion, optimizer, n_epochs, size)\n",
        "torch.save(model.state_dict(), \"model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-4hoPV4KJ20",
        "colab_type": "code",
        "outputId": "95a60e5b-47de-4536-dd8c-487f37f54313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "############################### Statistiques ################################\n",
        "\n",
        "#Predict for test data \n",
        "\n",
        "database.set_mode(\"test\")\n",
        "dataloader_val = DataLoader(database, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "test(model, dataloader_val, criterion, size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final loss : 0.04109051704406738 & accuracy : 0.5236\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}