{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D4G unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBZbfd5FTk5j",
        "colab_type": "code",
        "outputId": "5dc19e57-1454-44a4-ec7b-3d75d69cc27e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install pyrsgis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyrsgis in /usr/local/lib/python3.6/dist-packages (0.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQeHUtevvxaN",
        "colab_type": "code",
        "outputId": "fd61b21d-5d6c-4abe-9513-a3c6e19533f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######################### Import des libraries #######################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pyrsgis import raster\n",
        "from torch.utils.data import Dataset, DataLoader, sampler\n",
        "from pyrsgis.convert import changeDimension\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import scipy.signal\n",
        "import scipy.ndimage\n",
        "from os import path\n",
        "import numpy as np\n",
        "from time import time\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from copy import deepcopy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning! matplotlib_scalebar library not found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvuNIIpQJTUo",
        "colab_type": "code",
        "outputId": "409431ba-389b-4c32-a808-8f91aae15e36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44yhFLpUJjdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################## Parameters ############################\n",
        "\n",
        "stop = 1000\n",
        "epochs = 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N830fS93Jof2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Import des données #########################\n",
        "\n",
        "path = \"/content/drive/My Drive/D4G/2_Seredou_2017/\"\n",
        "\n",
        "Test = \"2_Image_Seredou_32bits_20170205/S2A_20170205_seredou_32bits.tif\"\n",
        "MSI = \"2_MSI_Seredou_20170205/S2A_20170205_seredou_ZE_MSI_89.tif\"\n",
        "Truth = \"GroundTruth_Seredou_20170205/GroundTruth_20170205_seredou_ZE_89.tif\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b1de3TRIDqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Fonctions auxiliaires #########################\n",
        "\n",
        "def divide_test_in_squares(size, img):\n",
        "    return [img[:,int(i % img.shape[0])*size:((int(i % img.shape[0])+1)*size), int(i // img.shape[0])*size:(int(i // img.shape[0])+1)*size] for i in range(int(img.shape[0] * img.shape[1] // size**2))]\n",
        "\n",
        "def divide_image_in_squares(size, img):\n",
        "    return [img[int(i % img.shape[0])*size:((int(i % img.shape[0])+1)*size), int(i // img.shape[0])*size:(int(i // img.shape[0])+1)*size] for i in range(int(img.shape[0] * img.shape[1] // size**2))]\n",
        "\n",
        "def get_window(img, center, size):\n",
        "    \n",
        "    window = torch.tensor([[0. for i in range(size)] for j in range(size)])\n",
        "    if center[0] + size // 2 < img.shape[0]:\n",
        "        i_begin = max(0,int(center[0]-size//2))\n",
        "        i_end = i_begin + size\n",
        "    else:\n",
        "        i_end = img.shape[0]\n",
        "        i_begin = i_end - size\n",
        "    if center[1] + size // 2 < img.shape[1]:\n",
        "        j_begin = max(0,int(center[1]-size//2))\n",
        "        j_end = j_begin + size\n",
        "    else:\n",
        "        j_end = img.shape[1]\n",
        "        j_begin = j_end - size\n",
        "\n",
        "    for i in range(i_begin, i_end):\n",
        "        for j in range(j_begin, j_end):\n",
        "            window[i - i_begin,j - j_begin] = float(img[i,j])\n",
        "    return window"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sta9I5a2KZcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Base de données #########################\n",
        "\n",
        "class OurDataset(Dataset):\n",
        "    \"\"\"This dataset includes .... \"\"\"\n",
        "    \n",
        "    def __init__(self, path, Test, MSI, Truth, size, percentage, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path: (str) path to the images directory.\n",
        "        \"\"\"\n",
        "        #get data\n",
        "        ds1, data_MSI = raster.read(path + MSI, bands='all')\n",
        "        ds2, data_test = raster.read(path + Test, bands='all')\n",
        "        ds3, data_truth = raster.read(path + Truth, bands='all')\n",
        "\n",
        "        data_MSI[data_MSI < 0] = 0\n",
        "        data_test[data_test < 0] = 0\n",
        "        data_truth[data_truth < 0] = 0\n",
        "\n",
        "        self.MSI = divide_image_in_squares(size, data_MSI)\n",
        "        self.Test = divide_test_in_squares(size, data_test)\n",
        "        self.Truth = divide_image_in_squares(size, data_truth)\n",
        "  \n",
        "        self.size = size\n",
        "        self.mode = \"train\"\n",
        "        self.id_train, self.id_test = train_test_split([i for i in range(len(self.Test))], test_size = percentage, random_state=42, shuffle=True)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.mode == \"train\":\n",
        "            return len(self.id_train)\n",
        "        else:\n",
        "            return len(self.id_test)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: (int) the index of the subject/session whom data is loaded.\n",
        "        Returns:\n",
        "            sample: (dict) corresponding data described by the following keys:\n",
        "                scan: 11 channels value\n",
        "                mask: true value\n",
        "        \"\"\"\n",
        "        if self.mode == \"train\":\n",
        "            idx = self.id_train[id]\n",
        "        else:\n",
        "            idx = self.id_test[id]\n",
        "\n",
        "        feature_data = torch.tensor([[[0. for i in range(11*10)] for j in range(self.Test[idx].shape[0])] for k in range(self.Test[idx].shape[1])])\n",
        "        feature_truth = np.array([[0 for j in range(self.Test[idx].shape[0])] for k in range(self.Test[idx].shape[1])])\n",
        "        \n",
        "        #On importe les données\n",
        "        for i in range(self.Test[idx].shape[0]):\n",
        "            for j in range(self.Test[idx].shape[1]):\n",
        "                feature_truth[i,j] = self.Truth[idx][i,j]\n",
        "                \n",
        "                msi = get_window(self.MSI[idx], (i,j), self.size // 2)\n",
        "                if msi.max() != 0:\n",
        "                    msi = msi/msi.max()\n",
        "                laplace_gauss = torch.tensor(scipy.ndimage.gaussian_laplace(msi.numpy(), sigma = 1))\n",
        "\n",
        "                feature_data[i,j,100] = float(self.MSI[idx][i,j])\n",
        "                feature_data[i,j,101] = msi.max()\n",
        "                feature_data[i,j,102] = msi.min()\n",
        "                feature_data[i,j,103] = msi.mean()\n",
        "                feature_data[i,j,104] = msi.std()\n",
        "                feature_data[i,j,105] = msi.median()\n",
        "                feature_data[i,j,106] = laplace_gauss.min()\n",
        "                feature_data[i,j,107] = laplace_gauss.max()\n",
        "                feature_data[i,j,108] = laplace_gauss.mean()\n",
        "                feature_data[i,j,109] = laplace_gauss.std()\n",
        "                \n",
        "                for k in range (10):\n",
        "                    test = get_window(self.Test[idx][k,:,:], (i,j), self.size // 2)\n",
        "                    if test.max() != 0:\n",
        "                        test = test/test.max()\n",
        "\n",
        "                    laplace_gauss = torch.tensor(scipy.ndimage.gaussian_laplace(test.numpy(), sigma = 1))\n",
        "\n",
        "                    feature_data[i,j,k*10] = float(self.Test[idx][k,i,j])\n",
        "                    feature_data[i,j,k*10 + 1] = test.max()\n",
        "                    feature_data[i,j,k*10 + 2] = test.min()\n",
        "                    feature_data[i,j,k*10 + 3] = test.mean()\n",
        "                    feature_data[i,j,k*10 + 4] = test.std()\n",
        "                    feature_data[i,j,k*10 + 5] = test.median()\n",
        "                    feature_data[i,j,k*10 + 6] = laplace_gauss.max()\n",
        "                    feature_data[i,j,k*10 + 7] = laplace_gauss.min()\n",
        "                    feature_data[i,j,k*10 + 8] = laplace_gauss.mean()\n",
        "                    feature_data[i,j,k*10 + 9] = laplace_gauss.std()\n",
        "        \n",
        "        sample = {'data': feature_data, 'mask': feature_truth}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Put all the transforms of the dataset in training mode\"\"\"\n",
        "        self.transform.train()\n",
        "\n",
        "    def set_mode(self, mode):\n",
        "        \"\"\"Change mode of the database\"\"\"\n",
        "        self.mode = mode\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Put all the transforms of the dataset in evaluation mode\"\"\"\n",
        "        self.transform.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9sNIa0dL1K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_activation(activation_type):\n",
        "    activation_type = activation_type.lower()\n",
        "    if hasattr(nn, activation_type):\n",
        "      return getattr(nn, activation_type)()\n",
        "    else:\n",
        "      return nn.ReLU()\n",
        "\n",
        "def _make_nConv(in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "  layers = []\n",
        "  layers.append(ConvBatchNorm(in_channels, out_channels, activation))\n",
        "\n",
        "  for _ in range(nb_Conv-1):\n",
        "      layers.append(ConvBatchNorm(out_channels, out_channels, activation))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class ConvBatchNorm(nn.Module):\n",
        "  \"\"\"(convolution => [BN] => ReLU)\"\"\"\n",
        "  \n",
        "  def __init__(self, in_channels, out_channels, activation='ReLU'):\n",
        "    super(ConvBatchNorm, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, \n",
        "                          kernel_size=3, padding=1)\n",
        "    self.norm = nn.BatchNorm2d(out_channels)\n",
        "    self.activation = get_activation(activation)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    out = self.norm(out)\n",
        "    return self.activation(out)\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "  \"\"\"Downscaling with maxpool convolution\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "    super(DownBlock, self).__init__()\n",
        "    self.maxpool = nn.MaxPool2d(2)\n",
        "    self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "        \n",
        "  def forward(self, x):\n",
        "    out = self.maxpool(x)\n",
        "    return self.nConvs(out)  \n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "  \"\"\"Upscaling then conv\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, nb_Conv, in_padding=0, out_padding=1, activation='ReLU'):\n",
        "    super(UpBlock, self).__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2,\\\n",
        "                                 padding=in_padding, output_padding=out_padding)\n",
        "    self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "  def forward(self, x, skip_x):\n",
        "    out = self.up(x)\n",
        "    x = torch.cat([out, skip_x], dim=1) \n",
        "    return self.nConvs(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpMUmfSIL3MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, n_channels, n_classes):\n",
        "    '''\n",
        "    n_channels : number of channels of the input. \n",
        "                    By default 4, because we have 4 modalities\n",
        "    n_labels : number of channels of the ouput.\n",
        "                  By default 4 (3 labels + 1 for the background)\n",
        "    '''\n",
        "    super(UNet, self).__init__()\n",
        "    self.n_channels = n_channels\n",
        "    self.n_classes = n_classes\n",
        "    self.inc = ConvBatchNorm(n_channels, 64)\n",
        "    self.down1 = DownBlock(64, 128, nb_Conv=2)\n",
        "    self.down2 = DownBlock(128, 256, nb_Conv=2)\n",
        "    self.down3 = DownBlock(256, 512, nb_Conv=2)\n",
        "    self.up1 = UpBlock(512+256, 256, nb_Conv=2, in_padding=0, out_padding=0)\n",
        "    self.up2 = UpBlock(256+128, 128, nb_Conv=2)\n",
        "    self.up3 = UpBlock(128+64, 64, nb_Conv=2, in_padding=0, out_padding=0)\n",
        "    self.outc = nn.Conv2d(64, n_classes, kernel_size=3, stride=1, padding=1)\n",
        "    self.last_activation = get_activation('Sigmoid')\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x1 = self.inc(x)\n",
        "    x2 = self.down1(x1)\n",
        "    x3 = self.down2(x2)\n",
        "    x4 = self.down3(x3)\n",
        "    x = self.up1(x3, x4)\n",
        "    x = self.up2(x, x2)\n",
        "    x = self.up3(x, x1)\n",
        "    logits = self.last_activation(self.outc(x))\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG7nihqFQEq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, criterion, optimizer, n_epochs):\n",
        "    \"\"\"\n",
        "    Method used to train a nn\n",
        "    \n",
        "    Args:\n",
        "        model: (nn.Module) the neural network\n",
        "        train_loader: (DataLoader) a DataLoader wrapping the dataset\n",
        "        criterion: (nn.Module) a method to compute the loss of a mini-batch of images\n",
        "        optimizer: (torch.optim) an optimization algorithm\n",
        "        n_epochs: (int) number of epochs performed during training\n",
        "\n",
        "    Returns:\n",
        "        best_model: (nn.Module) the trained neural network\n",
        "    \"\"\"\n",
        "    best_model = deepcopy(model)\n",
        "    train_best_loss = np.inf\n",
        "\n",
        "    batch_size = train_loader.batch_size\n",
        "    n = 10\n",
        "\n",
        "    n_batches = n//batch_size\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            images, mask = data['data'], data['mask']\n",
        "            scans = torch.flatten(mask)\n",
        "            outputs = torch.reshape(model(images), (scans.shape[0],4))\n",
        "            loss = criterion(outputs, scans)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader.dataset)\n",
        "        print('Epoch %i: loss = %f & accuracy = %f' % (epoch, mean_loss,int(torch.sum(torch.argmax(outputs,1) == scans))/scans.shape[0]))\n",
        "\n",
        "        if mean_loss < train_best_loss:\n",
        "            best_model = deepcopy(model)\n",
        "            train_best_loss = mean_loss\n",
        "    \n",
        "    return best_model\n",
        "\n",
        "def test(model, data_loader, criterion):\n",
        "    \"\"\"\n",
        "    Method used to test a CNN\n",
        "    \n",
        "    Args:\n",
        "        model: (nn.Module) the neural network\n",
        "        data_loader: (DataLoader) a DataLoader wrapping a MRIDataset\n",
        "        criterion: (nn.Module) a method to compute the loss of a mini-batch of images\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = data_loader.batch_size\n",
        "    n = 10000\n",
        "\n",
        "    n_batches = n//batch_size\n",
        "    nb_true = 0\n",
        "    nb_total = 0\n",
        "    size_loss = 0\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "             images, mask = data['data'], data['mask']\n",
        "             scans = torch.flatten(mask)\n",
        "             outputs = torch.reshape(model(images), (scans.shape[0],4))\n",
        "             loss = criterion(outputs, scans)\n",
        "             total_loss += loss.item()\n",
        "             size_loss += batch_size\n",
        "             nb_true += int(torch.sum(torch.argmax(outputs,1) == scans))\n",
        "             nb_total += scans.shape[0]\n",
        "\n",
        "    print(\"Final loss : {} & accuracy : {}\".format(str(total_loss/ size_loss), str(nb_true/nb_total)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM9FSIZxKOpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## Database ############################\n",
        "\n",
        "database = OurDataset(path, Test, MSI, Truth, 10, 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEVKRJieJtJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## Prétraitement ############################\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "database.set_mode(\"train\")\n",
        "dataloader_train = DataLoader(database, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "model = UNet(n_channels=10, n_classes=4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "n_epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsztqK9WQfRD",
        "colab_type": "code",
        "outputId": "fff3ecd3-3e62-47ef-8350-9f3563085d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "#################### Entrainement du modèle ##########################\n",
        "\n",
        "train(model, dataloader_train, criterion, optimizer, n_epochs)\n",
        "torch.save(model.state_dict(), \"model\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b240535141ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2df355fd5f04>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, n_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mscans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-80390fdbae23>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-0ab2c3839dfe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, skip_x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnConvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    776\u001b[0m         return F.conv_transpose2d(\n\u001b[1;32m    777\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given transposed=1, weight of size 512 512 2 2, expected input[10, 256, 2, 27] to have 512 channels, but got 256 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-4hoPV4KJ20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################### Statistiques ################################\n",
        "\n",
        "#Predict for test data\n",
        "\n",
        "database.set_mode(\"test\")\n",
        "dataloader_test = DataLoader(database, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "test(model, dataloader_test, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}