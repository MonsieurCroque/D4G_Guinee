{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D4G unet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBZbfd5FTk5j",
        "colab_type": "code",
        "outputId": "a8cb5425-5d64-444e-cf4c-629fdcf89d36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install pyrsgis"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyrsgis in /usr/local/lib/python3.6/dist-packages (0.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQeHUtevvxaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Import des libraries #######################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pyrsgis import raster\n",
        "from torch.utils.data import Dataset, DataLoader, sampler\n",
        "from pyrsgis.convert import changeDimension\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import scipy.signal\n",
        "import scipy.ndimage\n",
        "from os import path\n",
        "import numpy as np\n",
        "from time import time\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvuNIIpQJTUo",
        "colab_type": "code",
        "outputId": "572fe2e2-d5f8-40c8-e334-91b394323211",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44yhFLpUJjdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################## Parameters ############################\n",
        "\n",
        "stop = 1000\n",
        "epochs = 7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N830fS93Jof2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Import des données #########################\n",
        "\n",
        "path = \"/content/drive/My Drive/D4G/2_Seredou_2017/\"\n",
        "\n",
        "Test = \"2_Image_Seredou_32bits_20170205/S2A_20170205_seredou_32bits.tif\"\n",
        "MSI = \"2_MSI_Seredou_20170205/S2A_20170205_seredou_ZE_MSI_89.tif\"\n",
        "Truth = \"GroundTruth_Seredou_20170205/GroundTruth_20170205_seredou_ZE_89.tif\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b1de3TRIDqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Fonctions auxiliaires #########################\n",
        "\n",
        "def divide_test_in_squares(size, img):\n",
        "    return [img[:,int(i % img.shape[0])*size:((int(i % img.shape[0])+1)*size), int(i // img.shape[0])*size:(int(i // img.shape[0])+1)*size] for i in range(int(img.shape[0] * img.shape[1] // size**2))]\n",
        "\n",
        "def divide_image_in_squares(size, img):\n",
        "    return [img[int(i % img.shape[0])*size:((int(i % img.shape[0])+1)*size), int(i // img.shape[0])*size:(int(i // img.shape[0])+1)*size] for i in range(int(img.shape[0] * img.shape[1] // size**2))]\n",
        "\n",
        "def get_window(img, center, size):\n",
        "    \n",
        "    window = torch.tensor([[0. for i in range(size)] for j in range(size)])\n",
        "    if center[0] + size // 2 < img.shape[0]:\n",
        "        i_begin = max(0,int(center[0]-size//2))\n",
        "        i_end = i_begin + size\n",
        "    else:\n",
        "        i_end = img.shape[0]\n",
        "        i_begin = i_end - size\n",
        "    if center[1] + size // 2 < img.shape[1]:\n",
        "        j_begin = max(0,int(center[1]-size//2))\n",
        "        j_end = j_begin + size\n",
        "    else:\n",
        "        j_end = img.shape[1]\n",
        "        j_begin = j_end - size\n",
        "\n",
        "    for i in range(i_begin, i_end):\n",
        "        for j in range(j_begin, j_end):\n",
        "            window[i - i_begin,j - j_begin] = float(img[i,j])\n",
        "    return window"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sta9I5a2KZcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################### Base de données #########################\n",
        "\n",
        "class OurDataset(Dataset):\n",
        "    \"\"\"This dataset includes .... \"\"\"\n",
        "    \n",
        "    def __init__(self, path, Test, MSI, Truth, size, percentage, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            path: (str) path to the images directory.\n",
        "        \"\"\"\n",
        "        #get data\n",
        "        ds1, data_MSI = raster.read(path + MSI, bands='all')\n",
        "        ds2, data_test = raster.read(path + Test, bands='all')\n",
        "        ds3, data_truth = raster.read(path + Truth, bands='all')\n",
        "\n",
        "        data_MSI[data_MSI < 0] = 0\n",
        "        data_test[data_test < 0] = 0\n",
        "        data_truth[data_truth < 0] = 0\n",
        "\n",
        "        self.MSI = divide_image_in_squares(size, data_MSI)\n",
        "        self.Test = divide_test_in_squares(size, data_test)\n",
        "        self.Truth = divide_image_in_squares(size, data_truth)\n",
        "  \n",
        "        self.size = size\n",
        "        self.mode = \"train\"\n",
        "        self.id_train, self.id_test = train_test_split([i for i in range(len(self.Test))], test_size = percentage, random_state=42, shuffle=True)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.mode == \"train\":\n",
        "            return len(self.id_train)\n",
        "        else:\n",
        "            return len(self.id_test)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            idx: (int) the index of the subject/session whom data is loaded.\n",
        "        Returns:\n",
        "            sample: (dict) corresponding data described by the following keys:\n",
        "                scan: 11 channels value\n",
        "                mask: true value\n",
        "        \"\"\"\n",
        "        if self.mode == \"train\":\n",
        "            idx = self.id_train[id]\n",
        "        else:\n",
        "            idx = self.id_test[id]\n",
        "\n",
        "        feature_data = torch.tensor([[[0. for i in range(11*5)] for j in range(self.Test[idx].shape[0])] for k in range(self.Test[idx].shape[1])])\n",
        "        feature_truth = np.array([[0 for j in range(self.Test[idx].shape[0])] for k in range(self.Test[idx].shape[1])])\n",
        "        \n",
        "        #On importe les données\n",
        "        for i in range(self.Test[idx].shape[0]):\n",
        "            for j in range(self.Test[idx].shape[1]):\n",
        "                \n",
        "                feature_truth[i,j] = self.Truth[idx][i,j]\n",
        "\n",
        "                msi = get_window(self.MSI[idx], (i,j), self.size // 2)\n",
        "                msi = msi/msi.max()\n",
        "                feature_data[i,j,50] = float(self.MSI[idx][i,j])\n",
        "                feature_data[i,j,51] = msi.max()\n",
        "                feature_data[i,j,52] = msi.min()\n",
        "                feature_data[i,j,53] = msi.mean()\n",
        "                feature_data[i,j,54] = msi.std()\n",
        "                \n",
        "                for k in range (10):\n",
        "                    test = get_window(self.Test[idx][k,:,:], (i,j), self.size // 2)\n",
        "                    test = test/test.max()\n",
        "                    \n",
        "                    feature_data[i,j,k*5] = float(self.Test[idx][k,i,j])\n",
        "                    feature_data[i,j,k*5 + 1] = test.max()\n",
        "                    feature_data[i,j,k*5 + 2] = test.min()\n",
        "                    feature_data[i,j,k*5 + 3] = test.mean()\n",
        "                    feature_data[i,j,k*5 + 4] = test.std()\n",
        "        \n",
        "        sample = {'data': feature_data, 'mask': feature_truth}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Put all the transforms of the dataset in training mode\"\"\"\n",
        "        self.transform.train()\n",
        "\n",
        "    def set_mode(self, mode):\n",
        "        \"\"\"Change mode of the database\"\"\"\n",
        "        self.mode = mode\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Put all the transforms of the dataset in evaluation mode\"\"\"\n",
        "        self.transform.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9sNIa0dL1K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_activation(activation_type):\n",
        "    activation_type = activation_type.lower()\n",
        "    if hasattr(nn, activation_type):\n",
        "      return getattr(nn, activation_type)()\n",
        "    else:\n",
        "      return nn.ReLU()\n",
        "\n",
        "def _make_nConv(in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "  layers = []\n",
        "  layers.append(ConvBatchNorm(in_channels, out_channels, activation))\n",
        "\n",
        "  for _ in range(nb_Conv-1):\n",
        "      layers.append(ConvBatchNorm(out_channels, out_channels, activation))\n",
        "  return nn.Sequential(*layers)\n",
        "\n",
        "class ConvBatchNorm(nn.Module):\n",
        "  \"\"\"(convolution => [BN] => ReLU)\"\"\"\n",
        "  \n",
        "  def __init__(self, in_channels, out_channels, activation='ReLU'):\n",
        "    super(ConvBatchNorm, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, \n",
        "                          kernel_size=3, padding=1)\n",
        "    self.norm = nn.BatchNorm2d(out_channels)\n",
        "    self.activation = get_activation(activation)\n",
        "      \n",
        "  def forward(self, x):\n",
        "    out = self.conv(x)\n",
        "    out = self.norm(out)\n",
        "    return self.activation(out)\n",
        "\n",
        "class DownBlock(nn.Module):\n",
        "  \"\"\"Downscaling with maxpool convolution\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, nb_Conv, activation='ReLU'):\n",
        "    super(DownBlock, self).__init__()\n",
        "    self.maxpool = nn.MaxPool2d(2)\n",
        "    self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "        \n",
        "  def forward(self, x):\n",
        "    out = self.maxpool(x)\n",
        "    return self.nConvs(out)  \n",
        "\n",
        "class UpBlock(nn.Module):\n",
        "  \"\"\"Upscaling then conv\"\"\"\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, nb_Conv, in_padding=0, out_padding=1, activation='ReLU'):\n",
        "    super(UpBlock, self).__init__()\n",
        "    self.up = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2,\\\n",
        "                                 padding=in_padding, output_padding=out_padding)\n",
        "    self.nConvs = _make_nConv(in_channels, out_channels, nb_Conv, activation)\n",
        "\n",
        "  def forward(self, x, skip_x):\n",
        "    out = self.up(x)\n",
        "    x = torch.cat([out, skip_x], dim=1) \n",
        "    return self.nConvs(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpMUmfSIL3MD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, n_channels, n_classes):\n",
        "    '''\n",
        "    n_channels : number of channels of the input. \n",
        "                    By default 4, because we have 4 modalities\n",
        "    n_labels : number of channels of the ouput.\n",
        "                  By default 4 (3 labels + 1 for the background)\n",
        "    '''\n",
        "    super(UNet, self).__init__()\n",
        "    self.n_channels = n_channels\n",
        "    self.n_classes = n_classes\n",
        "    self.inc = ConvBatchNorm(n_channels, 64)\n",
        "    self.down1 = DownBlock(64, 128, nb_Conv=2)\n",
        "    self.down2 = DownBlock(128, 256, nb_Conv=2)\n",
        "    self.down3 = DownBlock(256, 512, nb_Conv=2)\n",
        "    self.up1 = UpBlock(512+256, 256, nb_Conv=2, in_padding=0, out_padding=0)\n",
        "    self.up2 = UpBlock(256+128, 128, nb_Conv=2)\n",
        "    self.up3 = UpBlock(128+64, 64, nb_Conv=2, in_padding=0, out_padding=0)\n",
        "    self.outc = nn.Conv2d(64, n_classes, kernel_size=3, stride=1, padding=1)\n",
        "    self.last_activation = get_activation('Sigmoid')\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x1 = self.inc(x)\n",
        "    x2 = self.down1(x1)\n",
        "    x3 = self.down2(x2)\n",
        "    x4 = self.down3(x3)\n",
        "    x = self.up1(x4, x3)\n",
        "    x = self.up2(x, x2)\n",
        "    x = self.up3(x, x1)\n",
        "    logits = self.last_activation(self.outc(x))\n",
        "    return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG7nihqFQEq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, criterion, optimizer, n_epochs):\n",
        "    \"\"\"\n",
        "    Method used to train a nn\n",
        "    \n",
        "    Args:\n",
        "        model: (nn.Module) the neural network\n",
        "        train_loader: (DataLoader) a DataLoader wrapping the dataset\n",
        "        criterion: (nn.Module) a method to compute the loss of a mini-batch of images\n",
        "        optimizer: (torch.optim) an optimization algorithm\n",
        "        n_epochs: (int) number of epochs performed during training\n",
        "\n",
        "    Returns:\n",
        "        best_model: (nn.Module) the trained neural network\n",
        "    \"\"\"\n",
        "    best_model = deepcopy(model)\n",
        "    train_best_loss = np.inf\n",
        "\n",
        "    batch_size = train_loader.batch_size\n",
        "    n = 10\n",
        "\n",
        "    n_batches = n//batch_size\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for i, data in enumerate(train_loader):\n",
        "            images, mask = data['data'], data['mask']\n",
        "            scans = torch.flatten(mask)\n",
        "            outputs = torch.reshape(model(images), (scans.shape[0],4))\n",
        "            loss = criterion(outputs, scans)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        mean_loss = total_loss / len(train_loader.dataset)\n",
        "        print('Epoch %i: loss = %f & accuracy = %f' % (epoch, mean_loss,torch.sum(torch.argmax(outputs,1) == scans)/scans.shape[0]))\n",
        "\n",
        "        if mean_loss < train_best_loss:\n",
        "            best_model = deepcopy(model)\n",
        "            train_best_loss = mean_loss\n",
        "    \n",
        "    return best_model\n",
        "\n",
        "def test(model, data_loader, criterion):\n",
        "    \"\"\"\n",
        "    Method used to test a CNN\n",
        "    \n",
        "    Args:\n",
        "        model: (nn.Module) the neural network\n",
        "        data_loader: (DataLoader) a DataLoader wrapping a MRIDataset\n",
        "        criterion: (nn.Module) a method to compute the loss of a mini-batch of images\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    batch_size = data_loader.batch_size\n",
        "    n = 10000\n",
        "\n",
        "    n_batches = n//batch_size\n",
        "    nb_true = 0\n",
        "    nb_total = 0\n",
        "    size_loss = 0\n",
        "    total_loss = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(data_loader):\n",
        "             images, mask = data['data'], data['mask']\n",
        "             scans = torch.flatten(mask)\n",
        "             outputs = torch.reshape(model(images), (scans.shape[0],4))\n",
        "             loss = criterion(outputs, scans)\n",
        "             total_loss += loss.item()\n",
        "             size_loss += batch_size\n",
        "             nb_true += int(torch.sum(torch.argmax(outputs,1) == scans))\n",
        "             nb_total += scans.shape[0]\n",
        "\n",
        "    print(\"Final loss : {} & accuracy : {}\".format(str(total_loss/ size_loss), str(nb_true/nb_total)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM9FSIZxKOpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## Database ############################\n",
        "\n",
        "database = OurDataset(path, Test, MSI, Truth, 10, 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEVKRJieJtJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "########################## Prétraitement ############################\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "database.set_mode(\"train\")\n",
        "dataloader_train = DataLoader(database, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "model = UNet(n_channels=10, n_classes=4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "n_epochs = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsztqK9WQfRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################### Entrainement du modèle ##########################\n",
        "\n",
        "train(model, dataloader_train, criterion, optimizer, n_epochs)\n",
        "torch.save(model.state_dict(), \"model\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-4hoPV4KJ20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "############################### Statistiques ################################\n",
        "\n",
        "#Predict for test data\n",
        "\n",
        "database.set_mode(\"test\")\n",
        "dataloader_test = DataLoader(database, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "test(model, dataloader_test, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}